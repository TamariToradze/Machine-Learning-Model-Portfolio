{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3816,"databundleVersionId":32105,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:00:00.610263Z","iopub.execute_input":"2025-07-29T20:00:00.610550Z","iopub.status.idle":"2025-07-29T20:00:02.004137Z","shell.execute_reply.started":"2025-07-29T20:00:00.610511Z","shell.execute_reply":"2025-07-29T20:00:02.003158Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/walmart-recruiting-store-sales-forecasting/train.csv.zip\n/kaggle/input/walmart-recruiting-store-sales-forecasting/sampleSubmission.csv.zip\n/kaggle/input/walmart-recruiting-store-sales-forecasting/stores.csv\n/kaggle/input/walmart-recruiting-store-sales-forecasting/features.csv.zip\n/kaggle/input/walmart-recruiting-store-sales-forecasting/test.csv.zip\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install dagshub\n!pip install mlflow\nimport dagshub\nimport mlflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:00:02.005787Z","iopub.execute_input":"2025-07-29T20:00:02.006288Z","iopub.status.idle":"2025-07-29T20:00:24.589786Z","shell.execute_reply.started":"2025-07-29T20:00:02.006261Z","shell.execute_reply":"2025-07-29T20:00:24.589013Z"}},"outputs":[{"name":"stdout","text":"Collecting dagshub\n  Downloading dagshub-0.6.2-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: PyYAML>=5 in /usr/local/lib/python3.11/dist-packages (from dagshub) (6.0.2)\nCollecting appdirs>=1.4.4 (from dagshub)\n  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: click>=8.0.4 in /usr/local/lib/python3.11/dist-packages (from dagshub) (8.2.1)\nRequirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.28.1)\nRequirement already satisfied: GitPython>=3.1.29 in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.1.44)\nRequirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (14.0.0)\nCollecting dacite~=1.6.0 (from dagshub)\n  Downloading dacite-1.6.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from dagshub) (8.5.0)\nCollecting gql[requests] (from dagshub)\n  Downloading gql-3.5.3-py2.py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.6.7)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.2.3)\nCollecting treelib>=1.6.4 (from dagshub)\n  Downloading treelib-1.8.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting pathvalidate>=3.0.0 (from dagshub)\n  Downloading pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.9.0.post0)\nRequirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from dagshub) (1.39.1)\nRequirement already satisfied: semver in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.0.4)\nCollecting dagshub-annotation-converter>=0.1.5 (from dagshub)\n  Downloading dagshub_annotation_converter-0.1.11-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (5.4.0)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (11.2.1)\nRequirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (2.11.7)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (4.14.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=3.1.29->dagshub) (4.0.12)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (4.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (3.10)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->dagshub) (0.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (2.19.2)\nRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from treelib>=1.6.4->dagshub) (1.17.0)\nRequirement already satisfied: botocore<1.40.0,>=1.39.1 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (1.39.1)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (1.0.1)\nRequirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (0.13.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->dagshub) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->dagshub) (0.9.0)\nCollecting graphql-core<3.2.7,>=3.2 (from gql[requests]->dagshub)\n  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.20.1)\nCollecting backoff<3.0,>=1.11.1 (from gql[requests]->dagshub)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: requests<3,>=2.26 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (2.32.4)\nRequirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.0.0)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (1.26.4)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (2025.2)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->dagshub) (1.3.1)\nRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.40.0,>=1.39.1->boto3->dagshub) (2.5.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.29->dagshub) (5.0.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub) (0.1.2)\nRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->dagshub) (25.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->dagshub) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->dagshub) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->dagshub) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->dagshub) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->dagshub) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->dagshub) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.5->dagshub) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.5->dagshub) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.5->dagshub) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.26->gql[requests]->dagshub) (3.4.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (1.1.0)\nRequirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.6.3)\nRequirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (0.3.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->dagshub) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->dagshub) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas->dagshub) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas->dagshub) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas->dagshub) (2024.2.0)\nDownloading dagshub-0.6.2-py3-none-any.whl (261 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.2/261.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\nDownloading dacite-1.6.0-py3-none-any.whl (12 kB)\nDownloading dagshub_annotation_converter-0.1.11-py3-none-any.whl (35 kB)\nDownloading pathvalidate-3.3.1-py3-none-any.whl (24 kB)\nDownloading treelib-1.8.0-py3-none-any.whl (30 kB)\nDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gql-3.5.3-py2.py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: appdirs, treelib, pathvalidate, graphql-core, dacite, backoff, gql, dagshub-annotation-converter, dagshub\n  Attempting uninstall: dacite\n    Found existing installation: dacite 1.9.2\n    Uninstalling dacite-1.9.2:\n      Successfully uninstalled dacite-1.9.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nydata-profiling 4.16.1 requires dacite>=1.8, but you have dacite 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed appdirs-1.4.4 backoff-2.2.1 dacite-1.6.0 dagshub-0.6.2 dagshub-annotation-converter-0.1.11 gql-3.5.3 graphql-core-3.2.6 pathvalidate-3.3.1 treelib-1.8.0\nCollecting mlflow\n  Downloading mlflow-3.1.4-py3-none-any.whl.metadata (29 kB)\nCollecting mlflow-skinny==3.1.4 (from mlflow)\n  Downloading mlflow_skinny-3.1.4-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.1)\nRequirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.16.2)\nRequirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7.2)\nRequirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\nRequirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.3)\nRequirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (19.0.1)\nRequirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.2.2)\nRequirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.3)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.41)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (8.2.1)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (3.1.1)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.4->mlflow)\n  Downloading databricks_sdk-0.60.0-py3-none-any.whl.metadata (39 kB)\nRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (0.115.13)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (3.1.44)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (8.7.0)\nCollecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.1.4->mlflow)\n  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.1.4->mlflow)\n  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: packaging<26 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (25.0)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (3.20.3)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (2.11.7)\nRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (6.0.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (2.32.4)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (4.14.0)\nRequirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (0.34.3)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\nRequirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.6)\nRequirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.0.2)\nRequirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.6)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.0.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.3)\nRequirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (2.40.3)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.1.4->mlflow) (0.46.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.4->mlflow) (4.0.12)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.4->mlflow) (3.23.0)\nCollecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.4->mlflow)\n  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.4->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.4->mlflow) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.4->mlflow) (0.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.4->mlflow) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.4->mlflow) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.4->mlflow) (2025.6.15)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==3.1.4->mlflow) (0.16.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3->mlflow) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.4->mlflow) (5.0.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (4.9.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.4->mlflow) (4.9.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.4->mlflow) (1.3.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (0.6.1)\nDownloading mlflow-3.1.4-py3-none-any.whl (24.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mlflow_skinny-3.1.4-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading databricks_sdk-0.60.0-py3-none-any.whl (677 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.0/677.0 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: gunicorn, graphql-relay, opentelemetry-api, graphene, opentelemetry-semantic-conventions, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\nSuccessfully installed databricks-sdk-0.60.0 graphene-3.4.3 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-3.1.4 mlflow-skinny-3.1.4 opentelemetry-api-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install dagshub mlflow\nimport dagshub\nimport mlflow\ndagshub.init(repo_owner='TamariToradze', repo_name='ML-Final', mlflow=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:00:24.590546Z","iopub.execute_input":"2025-07-29T20:00:24.591060Z","iopub.status.idle":"2025-07-29T20:01:27.797518Z","shell.execute_reply.started":"2025-07-29T20:00:24.591028Z","shell.execute_reply":"2025-07-29T20:01:27.796778Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: dagshub in /usr/local/lib/python3.11/dist-packages (0.6.2)\nRequirement already satisfied: mlflow in /usr/local/lib/python3.11/dist-packages (3.1.4)\nRequirement already satisfied: PyYAML>=5 in /usr/local/lib/python3.11/dist-packages (from dagshub) (6.0.2)\nRequirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from dagshub) (1.4.4)\nRequirement already satisfied: click>=8.0.4 in /usr/local/lib/python3.11/dist-packages (from dagshub) (8.2.1)\nRequirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.28.1)\nRequirement already satisfied: GitPython>=3.1.29 in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.1.44)\nRequirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (14.0.0)\nRequirement already satisfied: dacite~=1.6.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (1.6.0)\nRequirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from dagshub) (8.5.0)\nRequirement already satisfied: gql[requests] in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.5.3)\nRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.6.7)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.2.3)\nRequirement already satisfied: treelib>=1.6.4 in /usr/local/lib/python3.11/dist-packages (from dagshub) (1.8.0)\nRequirement already satisfied: pathvalidate>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.3.1)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.9.0.post0)\nRequirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from dagshub) (1.39.1)\nRequirement already satisfied: semver in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.0.4)\nRequirement already satisfied: dagshub-annotation-converter>=0.1.5 in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.1.11)\nRequirement already satisfied: mlflow-skinny==3.1.4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.4)\nRequirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.1)\nRequirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.16.2)\nRequirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\nRequirement already satisfied: graphene<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.4.3)\nRequirement already satisfied: gunicorn<24 in /usr/local/lib/python3.11/dist-packages (from mlflow) (23.0.0)\nRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7.2)\nRequirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\nRequirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (19.0.1)\nRequirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.2.2)\nRequirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.3)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.41)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (5.5.2)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (3.1.1)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (0.60.0)\nRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (0.115.13)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (8.7.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (1.36.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (1.36.0)\nRequirement already satisfied: packaging<26 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (25.0)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (3.20.3)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (2.11.7)\nRequirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (2.32.4)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (4.14.0)\nRequirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.4->mlflow) (0.34.3)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (5.4.0)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (11.2.1)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\nRequirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.6)\nRequirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.0.2)\nRequirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=3.1.29->dagshub) (4.0.12)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.6)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (4.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (3.10)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->dagshub) (0.16.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.0.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->dagshub) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (2.19.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.3)\nRequirement already satisfied: botocore<1.40.0,>=1.39.1 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (1.39.1)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (1.0.1)\nRequirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (0.13.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->dagshub) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->dagshub) (0.9.0)\nRequirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.20.1)\nRequirement already satisfied: backoff<3.0,>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (2.2.1)\nRequirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.0.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->dagshub) (1.3.1)\nRequirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (2.40.3)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.1.4->mlflow) (0.46.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.29->dagshub) (5.0.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.4->mlflow) (3.23.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub) (0.1.2)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.4->mlflow) (0.57b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.4->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.4->mlflow) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.4->mlflow) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.4->mlflow) (3.4.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (1.1.0)\nRequirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.6.3)\nRequirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (0.3.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3->mlflow) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (4.9.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (0.6.1)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n\nOpen the following link in your browser to authorize the client:\nhttps://dagshub.com/login/oauth/authorize?state=26e7421e-06f1-4040-90b8-de5735fc06a7&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=c8b6fc65f9b22463015e6a9113ad38ed1374a6c2be9419790ec5a58b70bdfa54\n\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Accessing as TamariToradze\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as TamariToradze\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Initialized MLflow to track repo \u001b[32m\"TamariToradze/ML-Final\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"TamariToradze/ML-Final\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Repository TamariToradze/ML-Final initialized!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository TamariToradze/ML-Final initialized!\n</pre>\n"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"features = pd.read_csv(\"/kaggle/input/walmart-recruiting-store-sales-forecasting/features.csv.zip\")\ntrain = pd.read_csv(\"/kaggle/input/walmart-recruiting-store-sales-forecasting/train.csv.zip\")\nstores = pd.read_csv(\"/kaggle/input/walmart-recruiting-store-sales-forecasting/stores.csv\")\ntest = pd.read_csv(\"/kaggle/input/walmart-recruiting-store-sales-forecasting/test.csv.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:01:27.798688Z","iopub.execute_input":"2025-07-29T20:01:27.798947Z","iopub.status.idle":"2025-07-29T20:01:28.207608Z","shell.execute_reply.started":"2025-07-29T20:01:27.798919Z","shell.execute_reply":"2025-07-29T20:01:28.206716Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom prophet import Prophet\nfrom sklearn.metrics import mean_absolute_error\nimport mlflow\nimport dagshub\nimport warnings\nfrom tqdm import tqdm\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nwarnings.filterwarnings('ignore')","metadata":{"id":"1NzxglB_2ZlF","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:01:28.209829Z","iopub.execute_input":"2025-07-29T20:01:28.210100Z","iopub.status.idle":"2025-07-29T20:01:29.261985Z","shell.execute_reply.started":"2025-07-29T20:01:28.210077Z","shell.execute_reply":"2025-07-29T20:01:29.261073Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\n\nclass Merger(BaseEstimator, TransformerMixin):\n  \n    def __init__(self, auxiliary_features, metadata_info):\n       \n        # Combine auxiliary data sources into unified reference dataset\n        self.reference_data = auxiliary_features.merge(\n            metadata_info, \n            how='inner', \n            on='Store'\n        )\n        # Ensure consistent datetime handling\n        self.reference_data['Date'] = pd.to_datetime(self.reference_data['Date'])\n    \n    def fit(self, X, y=None):\n        \"\"\"\n        Fit method required by sklearn interface.\n        No actual fitting needed for this transformer.\n        \"\"\"\n        return self\n    \n    def transform(self, X):\n    \n        # Create working copy to avoid modifying original data\n        enhanced_data = X.copy()\n        enhanced_data['Date'] = pd.to_datetime(enhanced_data['Date'])\n        \n        # Join with reference data using common keys\n        enriched_dataset = enhanced_data.merge(\n            self.reference_data,\n            how='inner',\n            on=['Store', 'Date', 'IsHoliday']\n        )\n        \n        # Apply consistent ordering for reproducible results\n        final_dataset = enriched_dataset.sort_values(\n            by=['Date', 'Store', 'Dept']\n        ).reset_index(drop=True)\n        \n        return final_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:01:29.263512Z","iopub.execute_input":"2025-07-29T20:01:29.263973Z","iopub.status.idle":"2025-07-29T20:01:29.271168Z","shell.execute_reply.started":"2025-07-29T20:01:29.263949Z","shell.execute_reply":"2025-07-29T20:01:29.270157Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class DateTimeFeatureExtractor(BaseEstimator, TransformerMixin):\n    \"\"\"Extracts basic datetime components and converts temperature units.\"\"\"\n    \n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        data = X.copy()\n        \n        # Temperature conversion to Celsius\n        if 'Temperature' in data.columns:\n            data['Temperature'] = (data['Temperature'] - 32) * (5.0 / 9.0)\n        \n        # Date component extraction\n        data['Day'] = data['Date'].dt.day\n        data['Month'] = data['Date'].dt.month\n        data['Year'] = data['Date'].dt.year\n        \n        return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:01:29.272591Z","iopub.execute_input":"2025-07-29T20:01:29.273065Z","iopub.status.idle":"2025-07-29T20:01:29.297761Z","shell.execute_reply.started":"2025-07-29T20:01:29.273035Z","shell.execute_reply":"2025-07-29T20:01:29.296841Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class HolidayFeatureGenerator(BaseEstimator, TransformerMixin):\n    \"\"\"Generates holiday-related features and proximity indicators.\"\"\"\n    \n    def __init__(self):\n        self.superbowl_dates = pd.to_datetime(['2010-02-12', '2011-02-11', '2012-02-10', '2013-02-08'])\n        self.laborday_dates = pd.to_datetime(['2010-09-10', '2011-09-09', '2012-09-07', '2013-09-06'])\n        self.thanksgiving_dates = pd.to_datetime(['2010-11-26', '2011-11-25', '2012-11-23', '2013-11-29'])\n        self.christmas_dates = pd.to_datetime(['2010-12-31', '2011-12-30', '2012-12-28', '2013-12-27'])\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        data = X.copy()\n        \n        # ISO calendar components for holiday detection\n        data['WeekNum'] = data['Date'].dt.isocalendar().week\n        data['CalendarYear'] = data['Date'].dt.year\n        \n        # Holiday week detection function\n        def check_holiday_week(dates, holiday_list):\n            holiday_week_set = set((d.isocalendar().week, d.year) for d in holiday_list)\n            return dates.apply(lambda d: (d.isocalendar().week, d.year) in holiday_week_set if pd.notnull(d) else False).astype(int)\n        \n        data['SuperbowlWeek'] = check_holiday_week(data['Date'], self.superbowl_dates)\n        data['LaborDayWeek'] = check_holiday_week(data['Date'], self.laborday_dates)\n        data['ThanksgivingWeek'] = check_holiday_week(data['Date'], self.thanksgiving_dates)\n        data['ChristmasWeek'] = check_holiday_week(data['Date'], self.christmas_dates)\n        \n        # Holiday proximity calculations using fixed anchor dates\n        thanksgiving_anchor = pd.to_datetime(data['Year'].astype(str) + \"-11-24\")\n        christmas_anchor = pd.to_datetime(data['Year'].astype(str) + \"-12-24\")\n        \n        data['Days_to_Thanksgiving'] = (thanksgiving_anchor - data['Date']).dt.days\n        data['Days_to_Christmas'] = (christmas_anchor - data['Date']).dt.days\n        \n        # Remove temporary columns\n        data = data.drop(columns=['WeekNum', 'CalendarYear'])\n        \n        return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:01:29.298737Z","iopub.execute_input":"2025-07-29T20:01:29.299058Z","iopub.status.idle":"2025-07-29T20:01:29.320658Z","shell.execute_reply.started":"2025-07-29T20:01:29.299022Z","shell.execute_reply":"2025-07-29T20:01:29.319625Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class TemporalFeatureEngineer(BaseEstimator, TransformerMixin):\n    \"\"\"Combined transformer that applies both datetime and holiday feature extraction.\"\"\"\n    \n    def __init__(self):\n        self.datetime_extractor = DateTimeFeatureExtractor()\n        self.holiday_generator = HolidayFeatureGenerator()\n    \n    def fit(self, X, y=None):\n        self.datetime_extractor.fit(X, y)\n        self.holiday_generator.fit(X, y)\n        return self\n    \n    def transform(self, X):\n        # Apply datetime features first\n        data = self.datetime_extractor.transform(X)\n        # Then apply holiday features\n        data = self.holiday_generator.transform(data)\n        return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:01:29.321732Z","iopub.execute_input":"2025-07-29T20:01:29.322090Z","iopub.status.idle":"2025-07-29T20:01:29.345199Z","shell.execute_reply.started":"2025-07-29T20:01:29.322056Z","shell.execute_reply":"2025-07-29T20:01:29.344048Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class NaFiller(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.promotional_cols = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n        self.economic_cols = ['CPI', 'Unemployment']\n        self.computed_means = {}\n    \n    def fit(self, X, y=None):\n        for column in self.economic_cols:\n            if column in X.columns:\n                self.computed_means[column] = X[column].mean()\n        return self\n    \n    def transform(self, X):\n        data = X.copy()\n        \n        # Fill promotional markdowns with 0\n        for column in self.promotional_cols:\n            if column in data.columns:\n                data[column] = data[column].fillna(0.0)\n        \n        # Fill economic indicators with computed mean\n        for column in self.economic_cols:\n            if column in data.columns and column in self.computed_means:\n                data[column] = data[column].fillna(self.computed_means[column])\n        \n        return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:01:29.346315Z","iopub.execute_input":"2025-07-29T20:01:29.346626Z","iopub.status.idle":"2025-07-29T20:01:29.364877Z","shell.execute_reply.started":"2025-07-29T20:01:29.346601Z","shell.execute_reply":"2025-07-29T20:01:29.363817Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class CategoryMapper(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.store_type_map = {'A': 3, 'B': 2, 'C': 1}\n        self.boolean_flag_map = {False: 0, True: 1}\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        data = X.copy()\n        \n        if 'Type' in data.columns:\n            data['Type'] = data['Type'].map(self.store_type_map)\n        \n        if 'IsHoliday' in data.columns:\n            data['IsHoliday'] = data['IsHoliday'].map(self.boolean_flag_map)\n        \n        return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:01:29.365925Z","iopub.execute_input":"2025-07-29T20:01:29.366231Z","iopub.status.idle":"2025-07-29T20:01:29.392261Z","shell.execute_reply.started":"2025-07-29T20:01:29.366201Z","shell.execute_reply":"2025-07-29T20:01:29.391246Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class StoreDataProcessor(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.processed_data = {}\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        self.processed_data = {}\n        for store_id in X['Store'].unique():\n            self.process_store_data(store_id, X)\n        return self.processed_data\n    \n    def process_store_data(self, store_num, X):\n        store_subset = X[X['Store'] == store_num].copy()\n        \n        # Detect if sales data is available (training vs test scenario)\n        sales_available = 'Weekly_Sales' in store_subset.columns\n        \n        if sales_available:\n            sum_fields = ['Weekly_Sales', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n        else:\n            sum_fields = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n        \n        first_fields = ['IsHoliday', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment',\n                       'Type', 'Size', 'Day', 'Month', 'Year', 'SuperbowlWeek',\n                       'LaborDayWeek', 'ThanksgivingWeek', 'ChristmasWeek',\n                       'Days_to_Thanksgiving', 'Days_to_Christmas']\n        \n        aggregation_rules = {}\n        \n        # Add summation rules for existing columns\n        for field in sum_fields:\n            if field in store_subset.columns:\n                aggregation_rules[field] = 'sum'\n        \n        # Add first-value rules for existing columns\n        for field in first_fields:\n            if field in store_subset.columns:\n                aggregation_rules[field] = 'first'\n        \n        consolidated = store_subset.groupby(['Date', 'Store']).agg(aggregation_rules).reset_index()\n        consolidated = consolidated.sort_values('Date').reset_index(drop=True)\n        \n        # Compute department proportions only when sales data exists\n        if sales_available:\n            dept_ratios = self.compute_dept_ratios(store_subset)\n        else:\n            dept_ratios = None\n        \n        self.processed_data[store_num] = (consolidated, dept_ratios)\n        return consolidated\n    \n    def compute_dept_ratios(self, store_subset):\n        dept_sales_totals = store_subset.groupby('Dept')['Weekly_Sales'].sum()\n        overall_total = store_subset['Weekly_Sales'].sum()\n        \n        if overall_total == 0:\n            dept_count = len(dept_sales_totals)\n            return {dept: 1.0/dept_count for dept in dept_sales_totals.index}\n        \n        dept_ratios_dict = (dept_sales_totals / overall_total).to_dict()\n        return dept_ratios_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:01:29.393090Z","iopub.execute_input":"2025-07-29T20:01:29.393328Z","iopub.status.idle":"2025-07-29T20:01:29.414924Z","shell.execute_reply.started":"2025-07-29T20:01:29.393307Z","shell.execute_reply":"2025-07-29T20:01:29.413819Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:01:29.416021Z","iopub.execute_input":"2025-07-29T20:01:29.416356Z","iopub.status.idle":"2025-07-29T20:01:29.448158Z","shell.execute_reply.started":"2025-07-29T20:01:29.416318Z","shell.execute_reply":"2025-07-29T20:01:29.447154Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('merge', Merger(features, stores)),\n    ('DateTimeFeatureExtractor', DateTimeFeatureExtractor()),\n    ('HolidayFeatureGenerator', HolidayFeatureGenerator()),\n    ('TemporalFeatureEngineer',TemporalFeatureEngineer()),\n    ('value_fill', NaFiller()),\n    ('cat_encoder', CategoryMapper()),\n    ('StoreDataProcessor', StoreDataProcessor())\n])","metadata":{"id":"Hvafta6j_exc","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:01:29.451523Z","iopub.execute_input":"2025-07-29T20:01:29.451892Z","iopub.status.idle":"2025-07-29T20:01:29.491635Z","shell.execute_reply.started":"2025-07-29T20:01:29.451870Z","shell.execute_reply":"2025-07-29T20:01:29.490833Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"train_dict = pipeline.fit_transform(train)\ntest_dict = pipeline.transform(test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:01:29.492587Z","iopub.execute_input":"2025-07-29T20:01:29.492947Z","iopub.status.idle":"2025-07-29T20:01:49.173289Z","shell.execute_reply.started":"2025-07-29T20:01:29.492916Z","shell.execute_reply":"2025-07-29T20:01:49.172608Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:01:49.174148Z","iopub.execute_input":"2025-07-29T20:01:49.174420Z","iopub.status.idle":"2025-07-29T20:01:49.178473Z","shell.execute_reply.started":"2025-07-29T20:01:49.174386Z","shell.execute_reply":"2025-07-29T20:01:49.177700Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"!pip install darts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:01:49.179323Z","iopub.execute_input":"2025-07-29T20:01:49.179627Z","iopub.status.idle":"2025-07-29T20:03:52.076337Z","shell.execute_reply.started":"2025-07-29T20:01:49.179596Z","shell.execute_reply":"2025-07-29T20:03:52.074627Z"}},"outputs":[{"name":"stdout","text":"Collecting darts\n  Downloading darts-0.36.0-py3-none-any.whl.metadata (56 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: holidays>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from darts) (0.75)\nRequirement already satisfied: joblib>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from darts) (1.5.1)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from darts) (3.7.2)\nRequirement already satisfied: narwhals>=1.25.1 in /usr/local/lib/python3.11/dist-packages (from darts) (1.44.0)\nCollecting nfoursid>=1.0.0 (from darts)\n  Downloading nfoursid-1.0.2-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from darts) (1.26.4)\nRequirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from darts) (2.2.3)\nCollecting pyod>=0.9.5 (from darts)\n  Downloading pyod-2.0.5-py3-none-any.whl.metadata (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from darts) (2.32.4)\nCollecting scikit-learn>=1.6.0 (from darts)\n  Downloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: scipy<1.16.0,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from darts) (1.15.3)\nRequirement already satisfied: shap>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from darts) (0.44.1)\nCollecting statsforecast>=1.4 (from darts)\n  Downloading statsforecast-2.0.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (29 kB)\nRequirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from darts) (0.14.4)\nRequirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.11/dist-packages (from darts) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from darts) (4.14.0)\nRequirement already satisfied: xarray>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from darts) (2025.3.1)\nCollecting xgboost>=2.1.4 (from darts)\n  Downloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\nRequirement already satisfied: pytorch-lightning>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from darts) (2.5.2)\nCollecting tensorboardX>=2.1 (from darts)\n  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from darts) (2.6.0+cu124)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from holidays>=0.11.1->darts) (2.9.0.post0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (3.0.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->darts) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->darts) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->darts) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->darts) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->darts) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->darts) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->darts) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->darts) (2025.2)\nRequirement already satisfied: numba>=0.51 in /usr/local/lib/python3.11/dist-packages (from pyod>=0.9.5->darts) (0.60.0)\nRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=1.5.0->darts) (6.0.2)\nRequirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (2025.5.1)\nRequirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=1.5.0->darts) (1.7.3)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=1.5.0->darts) (0.14.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->darts) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->darts) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->darts) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->darts) (2025.6.15)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->darts) (3.6.0)\nRequirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.11/dist-packages (from shap>=0.40.0->darts) (0.0.7)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap>=0.40.0->darts) (3.1.1)\nCollecting coreforecast>=0.0.12 (from statsforecast>=1.4->darts)\n  Downloading coreforecast-0.0.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\nCollecting fugue>=0.8.1 (from statsforecast>=1.4->darts)\n  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\nCollecting utilsforecast>=0.1.4 (from statsforecast>=1.4->darts)\n  Downloading utilsforecast-0.2.12-py3-none-any.whl.metadata (7.6 kB)\nRequirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.14.0->darts) (1.0.1)\nRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.1->darts) (3.20.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->darts)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->darts)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->darts)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->darts)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->darts)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->darts)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->darts)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->darts)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->darts)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->darts)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->darts) (1.3.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (3.12.13)\nCollecting triad>=0.9.7 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\nCollecting adagio>=0.2.4 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=1.5.0->darts) (75.2.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51->pyod>=0.9.5->darts) (0.43.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->holidays>=0.11.1->darts) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->darts) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->darts) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->darts) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->darts) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->darts) (2024.2.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.20.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->darts) (2024.2.0)\nRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts) (19.0.1)\nCollecting fs (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts)\n  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.11/dist-packages (from fs->triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts) (1.4.4)\nDownloading darts-0.36.0-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nfoursid-1.0.2-py3-none-any.whl (18 kB)\nDownloading pyod-2.0.5-py3-none-any.whl (200 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.6/200.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading statsforecast-2.0.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (340 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.0/340.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading coreforecast-0.0.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (285 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.8/285.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fugue-0.9.1-py3-none-any.whl (278 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading utilsforecast-0.2.12-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading adagio-0.2.6-py3-none-any.whl (19 kB)\nDownloading triad-0.9.8-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fs, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, triad, adagio, utilsforecast, scikit-learn, fugue, coreforecast, xgboost, tensorboardX, statsforecast, pyod, nfoursid, darts\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: xgboost\n    Found existing installation: xgboost 2.0.3\n    Uninstalling xgboost-2.0.3:\n      Successfully uninstalled xgboost-2.0.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nsklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed adagio-0.2.6 coreforecast-0.0.16 darts-0.36.0 fs-2.4.16 fugue-0.9.1 nfoursid-1.0.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyod-2.0.5 scikit-learn-1.7.1 statsforecast-2.0.2 tensorboardX-2.6.4 triad-0.9.8 utilsforecast-0.2.12 xgboost-3.0.2\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"!pip install scikit-learn==1.3.2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:03:52.078306Z","iopub.execute_input":"2025-07-29T20:03:52.078750Z","iopub.status.idle":"2025-07-29T20:03:59.461100Z","shell.execute_reply.started":"2025-07-29T20:03:52.078707Z","shell.execute_reply":"2025-07-29T20:03:59.459784Z"}},"outputs":[{"name":"stdout","text":"Collecting scikit-learn==1.3.2\n  Downloading scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.26.4)\nRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2024.2.0)\nDownloading scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-learn\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.7.1\n    Uninstalling scikit-learn-1.7.1:\n      Successfully uninstalled scikit-learn-1.7.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndarts 0.36.0 requires scikit-learn>=1.6.0, but you have scikit-learn 1.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scikit-learn-1.3.2\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nfrom prophet import Prophet\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\n\n# Define external variables for forecasting\nregressor_features = ['IsHoliday', 'SuperbowlWeek', 'LaborDayWeek', 'ThanksgivingWeek', 'ChristmasWeek']\n\n# Dictionary to store trained models\ntrained_models = {}\n\n# Train Prophet models for each store\nfor store in tqdm(train_dict.keys(), desc=\"Building Prophet forecasting models\"):\n   time_series_data, department_proportions = train_dict[store]\n   \n   try:\n       # Format data for Prophet requirements\n       prophet_df = time_series_data[['Date', 'Weekly_Sales']].copy()\n       prophet_df.rename(columns={'Date': 'ds', 'Weekly_Sales': 'y'}, inplace=True)\n       prophet_df['ds'] = pd.to_datetime(prophet_df['ds'])\n       \n       # Identify which regressors are present in the dataset\n       valid_regressors = []\n       for feature in regressor_features:\n           if feature in time_series_data.columns:\n               prophet_df[feature] = time_series_data[feature].values\n               valid_regressors.append(feature)\n       \n       # Organize data chronologically\n       prophet_df = prophet_df.sort_values('ds').reset_index(drop=True)\n       \n       # Configure Prophet forecasting model\n       forecaster = Prophet(\n           yearly_seasonality=True,\n           weekly_seasonality=False,\n           daily_seasonality=False,\n           changepoint_prior_scale=0.01,\n           seasonality_prior_scale=10.0,\n           holidays_prior_scale=15.0,\n           mcmc_samples=0,\n           interval_width=0.8,\n           growth='flat'\n       )\n       \n       # Include US holiday effects\n       forecaster.add_country_holidays(country_name='US')\n       \n       # Register external regressors\n       for feature in valid_regressors:\n           forecaster.add_regressor(feature)\n       \n       # Train the forecasting model\n       forecaster.fit(prophet_df)\n       \n       # Save trained model with metadata\n       trained_models[store] = (forecaster, department_proportions, valid_regressors)\n       \n   except Exception as error:\n       print(f\"Error training Prophet model for Store {store}: {error}\")\n       continue\n\nprint(f\"Completed training for {len(trained_models)} store forecasting models\")","metadata":{"id":"CIel5_DSJiuS","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:03:59.462737Z","iopub.execute_input":"2025-07-29T20:03:59.463199Z","iopub.status.idle":"2025-07-29T20:04:05.279674Z","shell.execute_reply.started":"2025-07-29T20:03:59.463112Z","shell.execute_reply":"2025-07-29T20:04:05.278823Z"}},"outputs":[{"name":"stderr","text":"Building Prophet forecasting models:   0%|          | 0/45 [00:00<?, ?it/s]20:04:01 - cmdstanpy - INFO - Chain [1] start processing\n20:04:01 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:   2%|▏         | 1/45 [00:01<01:10,  1.60s/it]20:04:01 - cmdstanpy - INFO - Chain [1] start processing\n20:04:01 - cmdstanpy - INFO - Chain [1] done processing\n20:04:01 - cmdstanpy - INFO - Chain [1] start processing\n20:04:01 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:   7%|▋         | 3/45 [00:01<00:20,  2.10it/s]20:04:01 - cmdstanpy - INFO - Chain [1] start processing\n20:04:01 - cmdstanpy - INFO - Chain [1] done processing\n20:04:01 - cmdstanpy - INFO - Chain [1] start processing\n20:04:01 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  11%|█         | 5/45 [00:01<00:10,  3.64it/s]20:04:01 - cmdstanpy - INFO - Chain [1] start processing\n20:04:01 - cmdstanpy - INFO - Chain [1] done processing\n20:04:01 - cmdstanpy - INFO - Chain [1] start processing\n20:04:01 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  16%|█▌        | 7/45 [00:02<00:07,  5.15it/s]20:04:01 - cmdstanpy - INFO - Chain [1] start processing\n20:04:01 - cmdstanpy - INFO - Chain [1] done processing\n20:04:01 - cmdstanpy - INFO - Chain [1] start processing\n20:04:01 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  20%|██        | 9/45 [00:02<00:05,  6.57it/s]20:04:01 - cmdstanpy - INFO - Chain [1] start processing\n20:04:01 - cmdstanpy - INFO - Chain [1] done processing\n20:04:01 - cmdstanpy - INFO - Chain [1] start processing\n20:04:01 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  24%|██▍       | 11/45 [00:02<00:04,  7.82it/s]20:04:01 - cmdstanpy - INFO - Chain [1] start processing\n20:04:01 - cmdstanpy - INFO - Chain [1] done processing\n20:04:02 - cmdstanpy - INFO - Chain [1] start processing\n20:04:02 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  29%|██▉       | 13/45 [00:02<00:03,  8.85it/s]20:04:02 - cmdstanpy - INFO - Chain [1] start processing\n20:04:02 - cmdstanpy - INFO - Chain [1] done processing\n20:04:02 - cmdstanpy - INFO - Chain [1] start processing\n20:04:02 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  33%|███▎      | 15/45 [00:02<00:03,  9.68it/s]20:04:02 - cmdstanpy - INFO - Chain [1] start processing\n20:04:02 - cmdstanpy - INFO - Chain [1] done processing\n20:04:02 - cmdstanpy - INFO - Chain [1] start processing\n20:04:02 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  38%|███▊      | 17/45 [00:02<00:02, 10.32it/s]20:04:02 - cmdstanpy - INFO - Chain [1] start processing\n20:04:02 - cmdstanpy - INFO - Chain [1] done processing\n20:04:02 - cmdstanpy - INFO - Chain [1] start processing\n20:04:02 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  42%|████▏     | 19/45 [00:03<00:02, 10.83it/s]20:04:02 - cmdstanpy - INFO - Chain [1] start processing\n20:04:02 - cmdstanpy - INFO - Chain [1] done processing\n20:04:02 - cmdstanpy - INFO - Chain [1] start processing\n20:04:02 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  47%|████▋     | 21/45 [00:03<00:02, 11.12it/s]20:04:02 - cmdstanpy - INFO - Chain [1] start processing\n20:04:02 - cmdstanpy - INFO - Chain [1] done processing\n20:04:02 - cmdstanpy - INFO - Chain [1] start processing\n20:04:02 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  51%|█████     | 23/45 [00:03<00:01, 11.45it/s]20:04:02 - cmdstanpy - INFO - Chain [1] start processing\n20:04:02 - cmdstanpy - INFO - Chain [1] done processing\n20:04:03 - cmdstanpy - INFO - Chain [1] start processing\n20:04:03 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  56%|█████▌    | 25/45 [00:03<00:01, 11.57it/s]20:04:03 - cmdstanpy - INFO - Chain [1] start processing\n20:04:03 - cmdstanpy - INFO - Chain [1] done processing\n20:04:03 - cmdstanpy - INFO - Chain [1] start processing\n20:04:03 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  60%|██████    | 27/45 [00:03<00:01, 11.72it/s]20:04:03 - cmdstanpy - INFO - Chain [1] start processing\n20:04:03 - cmdstanpy - INFO - Chain [1] done processing\n20:04:03 - cmdstanpy - INFO - Chain [1] start processing\n20:04:03 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  64%|██████▍   | 29/45 [00:03<00:01, 10.83it/s]20:04:03 - cmdstanpy - INFO - Chain [1] start processing\n20:04:03 - cmdstanpy - INFO - Chain [1] done processing\n20:04:03 - cmdstanpy - INFO - Chain [1] start processing\n20:04:03 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  69%|██████▉   | 31/45 [00:04<00:01, 10.69it/s]20:04:03 - cmdstanpy - INFO - Chain [1] start processing\n20:04:03 - cmdstanpy - INFO - Chain [1] done processing\n20:04:03 - cmdstanpy - INFO - Chain [1] start processing\n20:04:03 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  73%|███████▎  | 33/45 [00:04<00:01, 11.13it/s]20:04:03 - cmdstanpy - INFO - Chain [1] start processing\n20:04:03 - cmdstanpy - INFO - Chain [1] done processing\n20:04:03 - cmdstanpy - INFO - Chain [1] start processing\n20:04:03 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  78%|███████▊  | 35/45 [00:04<00:00, 11.18it/s]20:04:04 - cmdstanpy - INFO - Chain [1] start processing\n20:04:04 - cmdstanpy - INFO - Chain [1] done processing\n20:04:04 - cmdstanpy - INFO - Chain [1] start processing\n20:04:04 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  82%|████████▏ | 37/45 [00:04<00:00, 11.41it/s]20:04:04 - cmdstanpy - INFO - Chain [1] start processing\n20:04:04 - cmdstanpy - INFO - Chain [1] done processing\n20:04:04 - cmdstanpy - INFO - Chain [1] start processing\n20:04:04 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  87%|████████▋ | 39/45 [00:04<00:00, 11.69it/s]20:04:04 - cmdstanpy - INFO - Chain [1] start processing\n20:04:04 - cmdstanpy - INFO - Chain [1] done processing\n20:04:04 - cmdstanpy - INFO - Chain [1] start processing\n20:04:04 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  91%|█████████ | 41/45 [00:05<00:00, 11.86it/s]20:04:04 - cmdstanpy - INFO - Chain [1] start processing\n20:04:04 - cmdstanpy - INFO - Chain [1] done processing\n20:04:05 - cmdstanpy - INFO - Chain [1] start processing\n20:04:05 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models:  96%|█████████▌| 43/45 [00:05<00:00,  6.55it/s]20:04:05 - cmdstanpy - INFO - Chain [1] start processing\n20:04:05 - cmdstanpy - INFO - Chain [1] done processing\n20:04:05 - cmdstanpy - INFO - Chain [1] start processing\n20:04:05 - cmdstanpy - INFO - Chain [1] done processing\nBuilding Prophet forecasting models: 100%|██████████| 45/45 [00:05<00:00,  7.76it/s]","output_type":"stream"},{"name":"stdout","text":"Completed training for 45 store forecasting models\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"import mlflow\nimport dagshub\nimport pickle\nimport os\nfrom datetime import datetime\n\n# Initialize MLflow experiment tracking\nmlflow.set_experiment(\"Prophet_Forecasting\")\n\n# Begin MLflow tracking session\nwith mlflow.start_run(run_name=f\"Prophet_Training_Run_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n    \n    # Record experiment configuration\n    mlflow.log_param(\"forecasting_model\", \"Prophet\")\n    mlflow.log_param(\"methodology\", \"store_aggregated_approach\")\n    mlflow.log_param(\"external_features\", \", \".join(regressor_features))\n    mlflow.log_param(\"feature_count\", len(regressor_features))\n    mlflow.log_param(\"training_stores\", len(train_dict))\n    mlflow.log_param(\"trained_models\", len(trained_models))\n    mlflow.log_param(\"training_failures\", len(train_dict) - len(trained_models))\n    \n    # Record Prophet configuration parameters\n    mlflow.log_param(\"annual_patterns\", True)\n    mlflow.log_param(\"weekly_patterns\", False)\n    mlflow.log_param(\"daily_patterns\", False)\n    mlflow.log_param(\"trend_flexibility\", 0.01)\n    mlflow.log_param(\"seasonal_strength\", 10.0)\n    mlflow.log_param(\"holiday_strength\", 15.0)\n    mlflow.log_param(\"sampling_method\", 0)\n    mlflow.log_param(\"confidence_interval\", 0.8)\n    mlflow.log_param(\"trend_type\", \"flat\")\n    mlflow.log_param(\"holiday_calendar\", \"US\")\n    \n    # Calculate and log performance metrics\n    success_ratio = len(trained_models) / len(train_dict)\n    mlflow.log_metric(\"training_success_ratio\", success_ratio)\n    \n    # Analyze store-level information and calculate performance metrics\n    store_statistics = []\n    total_time_periods = 0\n    total_dept_count = 0\n    all_mape_scores = []\n    all_rmse_scores = []\n    \n    for store_key, (model, dept_data, features) in trained_models.items():\n        # Extract training data size\n        training_data = train_dict[store_key][0]\n        training_size = len(training_data)\n        dept_size = len(dept_data) if dept_data is not None else 0\n        \n        total_time_periods += training_size\n        total_dept_count += dept_size\n        \n        # Prepare data for evaluation\n        eval_df = training_data[['Date', 'Weekly_Sales']].copy()\n        eval_df.columns = ['ds', 'y']\n        eval_df['ds'] = pd.to_datetime(eval_df['ds'])\n        \n        # Add regressors for prediction\n        for feature in features:\n            if feature in training_data.columns:\n                eval_df[feature] = training_data[feature].values\n        \n        # Generate predictions on training data\n        try:\n            predictions = model.predict(eval_df)\n            actual_values = eval_df['y'].values\n            predicted_values = predictions['yhat'].values\n            \n            # Calculate MAPE (Mean Absolute Percentage Error)\n            mape = np.mean(np.abs((actual_values - predicted_values) / actual_values)) * 100\n            \n            # Calculate RMSE (Root Mean Square Error)\n            rmse = np.sqrt(np.mean((actual_values - predicted_values) ** 2))\n            \n            all_mape_scores.append(mape)\n            all_rmse_scores.append(rmse)\n            \n        except Exception as e:\n            print(f\"Error calculating metrics for Store {store_key}: {e}\")\n            mape, rmse = None, None\n        \n        store_info = {\n            'store_id': store_key,\n            'training_periods': training_size,\n            'department_count': dept_size,\n            'active_features': len(features),\n            'mape': mape,\n            'rmse': rmse\n        }\n        store_statistics.append(store_info)\n    \n    # Calculate and record aggregate statistics\n    if len(trained_models) > 0:\n        avg_periods = total_time_periods / len(trained_models)\n        avg_departments = total_dept_count / len(trained_models)\n        \n        # Calculate performance metrics\n        valid_mape_scores = [score for score in all_mape_scores if score is not None]\n        valid_rmse_scores = [score for score in all_rmse_scores if score is not None]\n        \n        if valid_mape_scores:\n            avg_mape = np.mean(valid_mape_scores)\n            median_mape = np.median(valid_mape_scores)\n            mlflow.log_metric(\"average_mape\", avg_mape)\n            mlflow.log_metric(\"median_mape\", median_mape)\n            mlflow.log_metric(\"best_mape\", min(valid_mape_scores))\n            mlflow.log_metric(\"worst_mape\", max(valid_mape_scores))\n        \n        if valid_rmse_scores:\n            avg_rmse = np.mean(valid_rmse_scores)\n            median_rmse = np.median(valid_rmse_scores)\n            mlflow.log_metric(\"average_rmse\", avg_rmse)\n            mlflow.log_metric(\"median_rmse\", median_rmse)\n            mlflow.log_metric(\"best_rmse\", min(valid_rmse_scores))\n            mlflow.log_metric(\"worst_rmse\", max(valid_rmse_scores))\n        \n        mlflow.log_metric(\"average_training_periods\", avg_periods)\n        mlflow.log_metric(\"average_departments\", avg_departments)\n        mlflow.log_metric(\"combined_departments\", total_dept_count)\n        \n        # Print comprehensive metrics summary\n        print(\"=\" * 60)\n        print(\"PROPHET MODEL TRAINING SUMMARY\")\n        print(\"=\" * 60)\n        print(f\"Experiment Name: Prophet_Forecasting\")\n        print(f\"Training Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n        print()\n        \n        print(\"TRAINING OVERVIEW:\")\n        print(f\"  • Total Stores in Dataset: {len(train_dict)}\")\n        print(f\"  • Successfully Trained Models: {len(trained_models)}\")\n        print(f\"  • Failed Training Attempts: {len(train_dict) - len(trained_models)}\")\n        print(f\"  • Training Success Rate: {success_ratio:.1%}\")\n        print()\n        \n        print(\"MODEL CONFIGURATION:\")\n        print(f\"  • Forecasting Algorithm: Prophet\")\n        print(f\"  • External Features Used: {', '.join(regressor_features)}\")\n        print(f\"  • Feature Count: {len(regressor_features)}\")\n        print(f\"  • Trend Type: Flat\")\n        print(f\"  • Holiday Calendar: US\")\n        print(f\"  • Confidence Interval: 80%\")\n        print()\n        \n        print(\"DATA STATISTICS:\")\n        print(f\"  • Average Training Periods per Store: {avg_periods:.1f}\")\n        print(f\"  • Average Departments per Store: {avg_departments:.1f}\")\n        print(f\"  • Total Departments Across All Stores: {total_dept_count}\")\n        print(f\"  • Total Training Data Points: {total_time_periods}\")\n        print()\n        \n        # Print performance metrics\n        if valid_mape_scores:\n            print(\"PERFORMANCE METRICS (MAPE - Mean Absolute Percentage Error):\")\n            print(f\"  • Average MAPE: {avg_mape:.2f}%\")\n            print(f\"  • Median MAPE: {median_mape:.2f}%\")\n            print(f\"  • Best MAPE: {min(valid_mape_scores):.2f}%\")\n            print(f\"  • Worst MAPE: {max(valid_mape_scores):.2f}%\")\n            print()\n        \n        print(\"TOP 5 STORES BY PERFORMANCE (Lowest MAPE):\")\n        valid_stores = [s for s in store_statistics if s['mape'] is not None]\n        if valid_stores:\n            sorted_by_mape = sorted(valid_stores, key=lambda x: x['mape'])[:5]\n            for i, store in enumerate(sorted_by_mape, 1):\n                print(f\"  {i}. Store {store['store_id']}: MAPE={store['mape']:.2f}%, \"\n                      f\"{store['training_periods']} periods\")\n        print()\n        \n        print(\"TOP 5 STORES BY TRAINING DATA SIZE:\")\n        sorted_stores = sorted(store_statistics, key=lambda x: x['training_periods'], reverse=True)[:5]\n        for i, store in enumerate(sorted_stores, 1):\n            mape_str = f\"MAPE={store['mape']:.2f}%\" if store['mape'] is not None else \"MAPE=N/A\"\n            print(f\"  {i}. Store {store['store_id']}: {store['training_periods']} periods, \"\n                  f\"{store['department_count']} depts, {mape_str}\")\n        \n        print(\"=\" * 60)\n    \n    else:\n        print(\"WARNING: No models were successfully trained!\")\n        mlflow.log_metric(\"average_training_periods\", 0)\n        mlflow.log_metric(\"average_departments\", 0)\n        mlflow.log_metric(\"combined_departments\", 0)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G5XoNa_BJuZB","outputId":"4bd4fbf0-f078-4e34-9731-803e1e6982b3","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:45:14.582146Z","iopub.execute_input":"2025-07-29T20:45:14.582976Z","iopub.status.idle":"2025-07-29T20:46:00.688406Z","shell.execute_reply.started":"2025-07-29T20:45:14.582942Z","shell.execute_reply":"2025-07-29T20:46:00.687372Z"}},"outputs":[{"name":"stdout","text":"============================================================\nPROPHET MODEL TRAINING SUMMARY\n============================================================\nExperiment Name: Prophet_Forecasting\nTraining Timestamp: 2025-07-29 20:45:58\n\nTRAINING OVERVIEW:\n  • Total Stores in Dataset: 45\n  • Successfully Trained Models: 45\n  • Failed Training Attempts: 0\n  • Training Success Rate: 100.0%\n\nMODEL CONFIGURATION:\n  • Forecasting Algorithm: Prophet\n  • External Features Used: IsHoliday, SuperbowlWeek, LaborDayWeek, ThanksgivingWeek, ChristmasWeek\n  • Feature Count: 5\n  • Trend Type: Flat\n  • Holiday Calendar: US\n  • Confidence Interval: 80%\n\nDATA STATISTICS:\n  • Average Training Periods per Store: 143.0\n  • Average Departments per Store: 74.0\n  • Total Departments Across All Stores: 3331\n  • Total Training Data Points: 6435\n\nPERFORMANCE METRICS (MAPE - Mean Absolute Percentage Error):\n  • Average MAPE: 5.02%\n  • Median MAPE: 4.50%\n  • Best MAPE: 2.13%\n  • Worst MAPE: 13.53%\n\nTOP 5 STORES BY PERFORMANCE (Lowest MAPE):\n  1. Store 37: MAPE=2.13%, 143 periods\n  2. Store 30: MAPE=3.08%, 143 periods\n  3. Store 10: MAPE=3.10%, 143 periods\n  4. Store 12: MAPE=3.15%, 143 periods\n  5. Store 31: MAPE=3.34%, 143 periods\n\nTOP 5 STORES BY TRAINING DATA SIZE:\n  1. Store 1: 143 periods, 77 depts, MAPE=4.50%\n  2. Store 2: 143 periods, 78 depts, MAPE=3.42%\n  3. Store 3: 143 periods, 72 depts, MAPE=5.64%\n  4. Store 4: 143 periods, 78 depts, MAPE=5.63%\n  5. Store 5: 143 periods, 72 depts, MAPE=5.27%\n============================================================\n🏃 View run Prophet_Training_Run_20250729_204514 at: https://dagshub.com/TamariToradze/ML-Final.mlflow/#/experiments/14/runs/874771890077448e80f3e104455e204a\n🧪 View experiment at: https://dagshub.com/TamariToradze/ML-Final.mlflow/#/experiments/14\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"max_training_date = pd.to_datetime(train['Date'].max())\n\ndef generate_prediction(sample_idx):\n    \"\"\"Generate forecast for a specific test sample\"\"\"\n    test_sample = test.iloc[sample_idx]\n    store_id = test_sample['Store']\n    department_id = test_sample['Dept']\n    forecast_date = pd.to_datetime(test_sample['Date'])\n    \n    try:\n        # Retrieve trained model and metadata\n        forecasting_model, department_weights, valid_features = trained_models[store_id]\n        \n        # Verify store exists in test dataset\n        if store_id not in test_dict:\n            return 1000.0\n            \n        # Load and prepare test data for the store\n        store_test_data, *_ = test_dict[store_id]\n        store_test_data = store_test_data.copy()\n        store_test_data['Date'] = pd.to_datetime(store_test_data['Date'])\n        store_test_data = store_test_data.sort_values('Date')\n        \n        # Filter data up to prediction date\n        filtered_data = store_test_data[store_test_data['Date'] <= forecast_date].copy()\n        if len(filtered_data) == 0:\n            return 1000.0\n        \n        # Construct input dataframe for Prophet prediction\n        prediction_input = {\n            'ds': filtered_data['Date'].tolist()\n        }\n        \n        # Include external regressors that are available\n        for feature_name in valid_features:\n            if feature_name in filtered_data.columns:\n                prediction_input[feature_name] = filtered_data[feature_name].tolist()\n        \n        input_df = pd.DataFrame(prediction_input)\n        \n        # Generate Prophet forecast\n        forecast_result = forecasting_model.predict(input_df)\n        forecast_result['ds'] = pd.to_datetime(forecast_result['ds'])\n        \n        # Extract prediction for target date\n        date_specific_forecast = forecast_result[forecast_result['ds'] == forecast_date]\n        \n        if len(date_specific_forecast) > 0:\n            base_prediction = max(0, date_specific_forecast['yhat'].iloc[0])\n            \n            # Apply department-specific weighting\n            if department_weights and department_id in department_weights.keys():\n                return base_prediction * department_weights[department_id]\n            elif department_weights:\n                return base_prediction / len(department_weights)\n            else:\n                return base_prediction\n        else:\n            return 1000.0  # Default value when date not found\n            \n    except Exception as error:\n        print(f\"Prediction failed for Store {store_id}, Department {department_id}: {error}\")\n        return 1000.0  # Error fallback value","metadata":{"id":"HNy0oItkJxOg","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:04:51.463180Z","iopub.execute_input":"2025-07-29T20:04:51.463576Z","iopub.status.idle":"2025-07-29T20:04:51.511306Z","shell.execute_reply.started":"2025-07-29T20:04:51.463543Z","shell.execute_reply":"2025-07-29T20:04:51.510250Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom datetime import datetime\n\ndef handle_store_predictions(store_info_tuple):\n    \"\"\"Generate all forecasts for a single store in batch mode\"\"\"\n    store_identifier, store_samples = store_info_tuple\n\n    # Verify model availability for this store\n    if store_identifier not in trained_models:\n        # Generate fallback results for all samples\n        prediction_results = []\n        for _, sample_row in store_samples.iterrows():\n            prediction_results.append({\n                'Id': f\"{sample_row['Store']}_{sample_row['Dept']}_{pd.to_datetime(sample_row['Date']).strftime('%Y-%m-%d')}\",\n                'Weekly_Sales': 1000.0\n            })\n        return prediction_results\n\n    try:\n        forecasting_model, department_ratios, model_features = trained_models[store_identifier]\n\n        # Retrieve aggregated test data for store\n        if store_identifier not in test_dict:\n            # Handle missing aggregated data\n            prediction_results = []\n            for _, sample_row in store_samples.iterrows():\n                prediction_results.append({\n                    'Id': f\"{sample_row['Store']}_{sample_row['Dept']}_{pd.to_datetime(sample_row['Date']).strftime('%Y-%m-%d')}\",\n                    'Weekly_Sales': 1000.0\n                })\n            return prediction_results\n\n        aggregated_data, _ = test_dict[store_identifier]\n        aggregated_data = aggregated_data.copy()\n        aggregated_data['Date'] = pd.to_datetime(aggregated_data['Date'])\n        aggregated_data = aggregated_data.sort_values('Date')\n\n        # Extract all required prediction dates\n        store_samples['Date'] = pd.to_datetime(store_samples['Date'])\n        prediction_dates = sorted(store_samples['Date'].unique())\n\n        # Build comprehensive input for Prophet\n        prophet_input = {'ds': prediction_dates}\n\n        # Map external features to all dates\n        for feature_col in model_features:\n            if feature_col in aggregated_data.columns:\n                # Extract feature values for each prediction date\n                feature_mapping = []\n                for target_date in prediction_dates:\n                    # Get most recent feature value up to target date\n                    historical_data = aggregated_data[aggregated_data['Date'] <= target_date]\n                    if len(historical_data) > 0:\n                        feature_mapping.append(historical_data[feature_col].iloc[-1])\n                    else:\n                        feature_mapping.append(0)  # Default value\n\n                prophet_input[feature_col] = feature_mapping\n\n        prophet_df = pd.DataFrame(prophet_input)\n\n        # Execute single batch prediction for all dates\n        batch_forecast = forecasting_model.predict(prophet_df)\n        batch_forecast['ds'] = pd.to_datetime(batch_forecast['ds'])\n\n        # Build lookup table for date-based predictions\n        prediction_lookup = dict(zip(batch_forecast['ds'], batch_forecast['yhat']))\n\n        # Generate final predictions for all test samples\n        prediction_results = []\n        for _, sample_row in store_samples.iterrows():\n            target_date = pd.to_datetime(sample_row['Date'])\n            department = sample_row['Dept']\n\n            # Retrieve store-level forecast\n            if target_date in prediction_lookup:\n                base_forecast = max(0, prediction_lookup[target_date])\n\n                # Calculate department-specific allocation\n                if department_ratios and department in department_ratios:\n                    adjusted_prediction = base_forecast * department_ratios[department]\n                elif department_ratios:\n                    adjusted_prediction = base_forecast / len(department_ratios)\n                else:\n                    adjusted_prediction = base_forecast\n            else:\n                adjusted_prediction = 1000.0\n\n            prediction_results.append({\n                'Id': f\"{sample_row['Store']}_{sample_row['Dept']}_{target_date.strftime('%Y-%m-%d')}\",\n                'Weekly_Sales': max(0, adjusted_prediction)\n            })\n\n        return prediction_results\n\n    except Exception as error:\n        print(f\"Batch forecasting failed for Store {store_identifier}: {error}\")\n        prediction_results = []\n        for _, sample_row in store_samples.iterrows():\n            prediction_results.append({\n                'Id': f\"{sample_row['Store']}_{sample_row['Dept']}_{pd.to_datetime(sample_row['Date']).strftime('%Y-%m-%d')}\",\n                'Weekly_Sales': 1000.0\n            })\n        return prediction_results\n\n# Group test data by store for parallel processing\nstores_grouped = list(test.groupby('Store'))\n\n# Execute parallel batch processing\nfinal_submission = []\nwith ThreadPoolExecutor(max_workers=4) as thread_pool:\n    prediction_tasks = [thread_pool.submit(handle_store_predictions, store_group) for store_group in stores_grouped]\n\n    for completed_task in tqdm(as_completed(prediction_tasks), total=len(prediction_tasks)):\n        store_predictions = completed_task.result()\n        final_submission.extend(store_predictions)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QZzrP-g0Jxp7","outputId":"722f2824-1dbb-4c73-b649-fcbae742e973","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:04:51.512752Z","iopub.execute_input":"2025-07-29T20:04:51.513025Z","iopub.status.idle":"2025-07-29T20:05:11.423319Z","shell.execute_reply.started":"2025-07-29T20:04:51.513005Z","shell.execute_reply":"2025-07-29T20:05:11.422354Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 45/45 [00:19<00:00,  2.27it/s]\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Use the existing batch processing function but simplify output\nstores_grouped = list(test.groupby('Store'))\nall_predictions = []\n\nprint(f\"Processing {len(stores_grouped)} stores in parallel...\")\n\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    futures = [executor.submit(handle_store_predictions, store_group) for store_group in stores_grouped]\n    \n    for future in tqdm(as_completed(futures), total=len(futures)):\n        store_results = future.result()\n        all_predictions.extend(store_results)\n\n# Convert to DataFrame and save\nforecast_df = pd.DataFrame(all_predictions)\nforecast_df = forecast_df.sort_values('Id').reset_index(drop=True)\nforecast_df.to_csv('prophet_predictions.csv', index=False)\n\nprint(f\"Saved {len(forecast_df)} predictions to prophet_predictions.csv\")\nprint(f\"Average prediction: ${forecast_df['Weekly_Sales'].mean():.2f}\")\nprint(f\"Fallback predictions (1000.0): {len(forecast_df[forecast_df['Weekly_Sales'] == 1000.0])}\")","metadata":{"id":"sEn1Sk_WXf6I","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T20:31:30.420964Z","iopub.execute_input":"2025-07-29T20:31:30.421322Z","iopub.status.idle":"2025-07-29T20:31:50.763196Z","shell.execute_reply.started":"2025-07-29T20:31:30.421294Z","shell.execute_reply":"2025-07-29T20:31:50.762190Z"}},"outputs":[{"name":"stdout","text":"Processing 45 stores in parallel...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 45/45 [00:19<00:00,  2.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 115064 predictions to prophet_predictions.csv\nAverage prediction: $16230.79\nFallback predictions (1000.0): 0\n","output_type":"stream"}],"execution_count":27}]}